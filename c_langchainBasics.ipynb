{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client=OpenAI(openai_api_key='ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zero shot prompting\n",
    "prompt=\"can you tell me total number of country in aisa? can you give me top 10 contry name?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(client.predict(prompt).strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "prompt templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template_name = PromptTemplate(\n",
    "    input_variables=['city'],\n",
    "    template = \"Can you tell me the population of {city}?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Can you tell me the population of London?'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template_name.format(city = 'London')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate.from_template(\"what is a good company that makes {product}?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt.format(product = 'cars').strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt4 = \"can u tell who won the recent world cup?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.predict(prompt4).strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "will extract real time info using serp api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "serapikey = \"ok2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentType, load_tools, initialize_agent\n",
    "from langchain.llms import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(openai_api_key=\"ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tool = load_tools([\"serpapi\"], serp_api_key = serapikey, llm = client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = initialize_agent(tool, client, AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.run(\"who won the recent cricket world cup?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tool2 = load_tools([\"wikipedia\"], llm = client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent2 = initialize_agent(tool, client, AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose = True)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent2.run(\"give me the recent cricket world cup winner\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(openai_api_key=\"ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate(\n",
    "    input_variables=['product'],\n",
    "    template=\"Can you tell me the top 5 companies that make {product}?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = LLMChain(llm = client, prompt = prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain.run(product = \"skateboards\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sequential chaining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import SequentialChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt1 = PromptTemplate(\n",
    "    input_variables=['cuisine'],\n",
    "    template=\"suggest a restaurant name for {'cuisine} cuisine\"\n",
    ")\n",
    "\n",
    "prompt2 = PromptTemplate(\n",
    "    input_variables=['restaurant_name'],\n",
    "    template=\"suggest some menu items for {'restaurant_name'}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_chain = LLMChain(llm = client, prompt = prompt1, output_key = 'restaurant_name')\n",
    "menu_chain = LLMChain(llm = client, prompt = prompt2, output_key = 'menu_items')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chainseq = SequentialChain(chains = [name_chain, menu_chain],\n",
    "                           input_variables = ['cuisine'],\n",
    "                           output_variables = ['restaurant_name', 'menu_items'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chainseq({\"cuisine\" : \"Italian\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "doc loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = PyPDFLoader(r\"C:\\Users\\parth\\Downloads\\Parth_s_Resume_AI.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_community.document_loaders.pdf.PyPDFLoader at 0x13bbd620210>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pages = loader.load_and_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='Parth Singh\n",
      "+91-9685771374 | parthsin10@gmail.com | LinkedIn | GitHub\n",
      "Experience\n",
      "Amazon Bengaluru, KA\n",
      "Applied Scientist Intern June 2025 - Nov 2025\n",
      "Education\n",
      "Indian Institute of Information Technology (IIIT), Nagpur Nagpur, MH\n",
      "Bachelor of Technology (BTech) in Electronics and Communication Engineering(IoT)| CGPA : 9.1 2022 – 2026\n",
      "MG Convent School Lucknow, UP\n",
      "CBSE Class 12th (Percentage : 95.6) 2021 – 2022\n",
      "Achievements\n",
      "Placed 50th in Amazon ML Challenge out of 78,000 participants. | link 2024\n",
      "Placed in top 5 percentile in Adobe Gen-Solve Hackathon out of 60,000 participants. | link 2024\n",
      "1st Place in Technalytics - Data/Business Analytics competition at Technex’24(IIT BHU). | link 2024\n",
      "3rd Place in Vista - CNN competition at CodeFest’24(IIT BHU). | link 2024\n",
      "Projects\n",
      "Cold Mail Generator for Services Companies | Python, Streamlit, LangChain, GROQ API, Vector Database\n",
      "• Developed a tool that extracts job listings from company career pages and generates personalized cold emails\n",
      "tailored to each job description, leveraging GROQ and LangChain.\n",
      "• Integrated a vector database to dynamically link relevant portfolio content, ensuring highly customized and\n",
      "targeted communication with prospective clients.\n",
      "• Implemented a user-friendly interface using Streamlit, simplifying the process for business development executives\n",
      "to generate emails in real-time.\n",
      "• Enhanced outreach efficiency for software development companies by automating the cold email process, reducing\n",
      "manual effort and improving response rates.\n",
      "• Ensured secure and scalable API integration using GROQ API for job listing extraction, adhering to best practices\n",
      "for data handling and privacy.\n",
      "AI-Powered Customer Support and Insights Platform | Python, Llama - 3.1, Tableau, PostgreSQL, Docker, AWS\n",
      "• Utilized Llama - 3.1 LLM for end-to-end customer query processing and sentiment analysis, automating 80% of\n",
      "interactions with 95% accuracy.\n",
      "• Integrated Tableau dashboards for real-time visualization of query metrics, sentiment trends, and support\n",
      "performance, enhancing insight accuracy by 40%.\n",
      "• Aimed to manage up to 1 TB of customer interaction data using PostgreSQL for efficient data handling and\n",
      "retrieval.\n",
      "• Deployed it on AWS with Docker, enabling scalable support for 100,000+ users and maintaining 99.9% uptime.\n",
      "Technical Skills\n",
      "CourseWorks: Deep Learning, Machine Learning, Data Analytics, Data Structures, Object Oriented Programming,\n",
      "Database Management System, Computer Networks, Internet of Things\n",
      "Programming Languages: Python, Java, C++, R, SQL\n",
      "Tools/Platforms:: GitHub, Docker, AWS, Ubuntu, PostgreSQL\n",
      "Libraries: TensorFlow, Pytorch, scikit-learn, OpenCV, Mediapipe, Flask, Huggingface Transformers\n",
      "Certifications\n",
      "Stanford University Machine Learning Specialization | link 2024\n",
      "Google Data Analytics Professional Certificate | link 2023\n",
      "Positions of Responsibility\n",
      "Head of Student Placement Cell September 2023 – Present\n",
      "Training and Placement Cell, IIIT Nagpur' metadata={'source': 'C:\\\\Users\\\\parth\\\\Downloads\\\\Parth_s_Resume_AI.pdf', 'page': 0}\n"
     ]
    }
   ],
   "source": [
    "print(pages[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
